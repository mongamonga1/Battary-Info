# -*- coding: utf-8 -*-
"""ì°¨ëª…ë³„ K-means êµ°ì§‘ ë¶„ì„ (k ìë™ì„ ì •, ê°€ë¡œ ìŠ¤í¬ë¡¤, ì €ê°€ GPT ìš”ì•½/Word Export - Chat Completions)"""
import warnings
warnings.filterwarnings("ignore")

import os, base64
from io import BytesIO
from pathlib import Path
from math import pi
import time

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

# --- OpenAI secrets í—¬í¼: [openai] ì„¹ì…˜/ë‹¨ì¼ í‚¤/í™˜ê²½ë³€ìˆ˜ ëª¨ë‘ ì§€ì› ---
def get_openai_conf():
    """
    ë°˜í™˜: (api_key:str|None, model_name:str|None)
    - Streamlit Secretsì˜ [openai].api_key / [openai].model ìš°ì„ 
    - OPENAI_API_KEY(ë‹¨ì¼ í‚¤)ë„ í—ˆìš©
    - í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY ë„ ë§ˆì§€ë§‰ ë³´ë£¨
    """
    api_key = None
    model_name = None

    # 1) [openai] ì„¹ì…˜
    if hasattr(st, "secrets") and "openai" in st.secrets:
        sect = st.secrets["openai"]
        api_key = sect.get("api_key") or api_key
        model_name = sect.get("model") or model_name

    # 2) ë‹¨ì¼ í‚¤ë„ í—ˆìš©
    if hasattr(st, "secrets"):
        api_key = api_key or st.secrets.get("OPENAI_API_KEY")

    # 3) í™˜ê²½ë³€ìˆ˜
    import os
    api_key = api_key or os.environ.get("OPENAI_API_KEY")

    return api_key, model_name

# â”€â”€ ì„ íƒ ë¼ì´ë¸ŒëŸ¬ë¦¬(ìˆìœ¼ë©´ í™œìš©: ë´ë“œë¡œê·¸ë¨/ì—˜ë³´ìš°)
try:
    from scipy.cluster.hierarchy import linkage
    _has_scipy = True
except Exception:
    _has_scipy = False

try:
    from yellowbrick.cluster import KElbowVisualizer
    _has_yb = True
except Exception:
    _has_yb = False

# â”€â”€ Word Export
from docx import Document
from docx.shared import Inches, Pt
from docx.oxml.ns import qn

# â”€â”€ OpenAI (Chat Completions)
try:
    from openai import OpenAI
    _has_openai = True
except Exception:
    _has_openai = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê¸°ë³¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mpl.rcParams["font.family"] = "DejaVu Sans"
mpl.rcParams["axes.unicode_minus"] = False
st.header("ğŸš— ì°¨ëª…ë³„ K-means êµ°ì§‘ ë¶„ì„")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë°ì´í„° ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_PATH = Path("data/SoH_NCM_Dataset_selected_Fid_ë°_ë°°í„°ë¦¬ë“±ê¸‰ì—´ì¶”ê°€.xlsx")
uploaded = st.sidebar.file_uploader("ì—‘ì…€ ì—…ë¡œë“œ(ì„ íƒ)", type=["xlsx"])

def load_excel(path_or_buffer) -> pd.DataFrame:
    df = pd.read_excel(path_or_buffer, engine="openpyxl")
    df.columns = df.columns.map(lambda x: str(x).strip())
    return df

if uploaded:
    df_raw = load_excel(uploaded)
    st.success("ì—…ë¡œë“œí•œ íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
elif DATA_PATH.exists():
    df_raw = load_excel(DATA_PATH)
else:
    st.error("ê¸°ë³¸ ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì»¬ëŸ¼ í‘œì¤€í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    def pick_first(cands):
        for c in cands:
            if c in out.columns: return c
        return None
    mapping = {}
    schema = [
        ("Model",       ["ì°¨ëª…", "ë°°í„°ë¦¬ì¢…ë¥˜", "ì°¨ì¢…", "ëª¨ë¸"]),
        ("Age",         ["ì‚¬ìš©ì—°ìˆ˜(t)", "ì‚¬ìš©ì—°ìˆ˜", "ì—°ì‹"]),
        ("SoH",         ["SoH_pred(%)", "SoH(%)", "SOH"]),
        ("Price",       ["ì¤‘ê³ ê±°ë˜ê°€ê²©", "ê°œë‹¹ê°€ê²©", "ê±°ë˜ê¸ˆì•¡", "ê°€ê²©"]),
        ("CellBalance", ["ì…€ ê°„ ê· í˜•", "ì…€ê°„ê· í˜•"]),
    ]
    for std,cands in schema:
        src = pick_first(cands)
        if src: mapping[src] = std
    out = out.rename(columns=mapping)

    # ì¤‘ë³µ ì—´ ì œê±°
    if out.columns.duplicated().any():
        out = out.loc[:, ~out.columns.duplicated()]

    # ë²”ì£¼ ë§¤í•‘
    if "CellBalance" in out.columns:
        out["CellBalance"] = (
            out["CellBalance"]
              .map({"ìš°ìˆ˜":"Good","ì •ìƒ":"Normal","ê²½ê³ ":"Warning","ì‹¬ê°":"Critical"})
              .fillna(out["CellBalance"])
        )

    # ìˆ«ì ì •ë¦¬
    if "Price" in out.columns:
        out["Price"] = (out["Price"].astype(str)
                        .str.replace(r"[^\d.\-]", "", regex=True)
                        .pipe(pd.to_numeric, errors="coerce"))
    if "Age" in out.columns:
        out["Age"] = pd.to_numeric(out["Age"], errors="coerce")
    if "SoH" in out.columns:
        out["SoH"] = pd.to_numeric(out["SoH"], errors="coerce")
    return out

df = normalize_columns(df_raw)

# í•„ìˆ˜/ìˆ˜ì¹˜ ì»¬ëŸ¼ í™•ì¸
if "Model" not in df.columns:
    st.error("ì—‘ì…€ì— 'ì°¨ëª…/ë°°í„°ë¦¬ì¢…ë¥˜/ì°¨ì¢…/ëª¨ë¸' ì¤‘ í•˜ë‚˜ê°€ ì—†ì–´ Model ì»¬ëŸ¼ì„ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

num_pool = [c for c in ["Age","SoH","Price"] if c in df.columns]
if len(num_pool) < 2:
    st.error(f"ìˆ˜ì¹˜ ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤(í•„ìš”â‰¥2). í˜„ì¬: {num_pool}")
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‚¬ì´ë“œë°” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
models        = sorted(df["Model"].dropna().astype(str).unique())
choice        = st.sidebar.selectbox("ì°¨ëª… ì„ íƒ", models)
show_tsne     = st.sidebar.checkbox("t-SNE 2D ì¶”ê°€", value=True)
show_pca3     = st.sidebar.checkbox("PCA 3D ì¶”ê°€", value=False)
perplexity    = st.sidebar.slider("t-SNE perplexity", 5, 50, 30, 1)
show_profiles = st.sidebar.checkbox("ì¶”ê°€ í”„ë¡œíŒŒì¼(ê°€ë¡œ ìŠ¤í¬ë¡¤)", value=True)

# ğŸ’¸ ë¹„ìš© ì˜µì…˜ (ìµœì†Œ ê³¼ê¸ˆ êµ¬ì¡°)
st.sidebar.markdown("### ğŸ’¸ ë¹„ìš© ì˜µì…˜")
cost_saver = st.sidebar.checkbox("ë¹„ìš© ì ˆê° ëª¨ë“œ(ì €ê°€ ëª¨ë¸Â·ì§§ì€ ì‘ë‹µ)", value=True)
DEFAULT_MODEL = "gpt-4o-mini"

# Secrets/í™˜ê²½ë³€ìˆ˜ì—ì„œ í‚¤Â·ëª¨ë¸ ì½ê¸°
_api_key, _model_from_secret = get_openai_conf()
MODEL_NAME = _model_from_secret or DEFAULT_MODEL
MAX_TOKENS = 320 if cost_saver else 600

TEMPERATURE = st.sidebar.slider("ìš”ì•½ temperature", 0.0, 1.0, 0.2, 0.05)
MAX_TOKENS  = 320 if cost_saver else 600

# ìƒíƒœ í‘œì‹œ(ì„ íƒ)
if _api_key:
    st.sidebar.success(f"âœ… GPT ì‚¬ìš© ê°€ëŠ¥ (ëª¨ë¸: {MODEL_NAME})")
else:
    st.sidebar.warning("ğŸ”’ OPENAI_API_KEY ë¯¸ì„¤ì • â†’ ë¡œì»¬ ìš”ì•½ìœ¼ë¡œ ëŒ€ì²´")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ëª¨ë¸ ë°ì´í„° ì¤€ë¹„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
sub_all = df[df["Model"].astype(str) == str(choice)].copy().dropna(subset=num_pool)
n = len(sub_all)
if n < 3:
    st.warning(f"'{choice}' ìœ íš¨ í‘œë³¸ì´ {n}ê±´ì´ë¼ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤(â‰¥3 í•„ìš”).")
    st.stop()

ks = list(range(2, min(10, n)))

preproc = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), num_pool),
        ("cat", OneHotEncoder(drop="first", handle_unknown="ignore"),
         ["CellBalance"] if "CellBalance" in sub_all.columns else []),
    ],
    remainder="drop",
)
X = preproc.fit_transform(sub_all)
if hasattr(X, "toarray"): X = X.toarray()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ k = Silhouette + Elbow + Dendrogram â†’ ì¤‘ì•™ê°’ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def choose_k_multi(X, ks):
    votes = {}
    # 1) Silhouette
    try:
        sil_scores = [silhouette_score(
            X, KMeans(n_clusters=k, random_state=42, n_init=10).fit_predict(X)
        ) for k in ks if k < len(X)]
        if sil_scores:
            votes["silhouette"] = ks[int(np.argmax(sil_scores))]
    except Exception:
        pass
    # 2) Elbow
    try:
        if _has_yb:
            viz = KElbowVisualizer(KMeans(random_state=42, n_init=10), k=ks, metric="distortion", timings=False)
            viz.fit(X)
            if viz.elbow_value_ is not None:
                votes["elbow"] = int(viz.elbow_value_)
        else:
            inertias = [KMeans(n_clusters=k, random_state=42, n_init=10).fit(X).inertia_ for k in ks]
            if len(inertias) >= 2:
                diffs = np.diff(inertias)
                idx = int(np.argmax(diffs))
                votes["elbow"] = ks[idx+1] if idx+1 < len(ks) else ks[-1]
    except Exception:
        pass
    # 3) Dendrogram gap
    try:
        if _has_scipy:
            m = X.shape[0]
            idx = np.arange(m if m <= 200 else 200)  # ì• 200ê°œ ìƒ˜í”Œ (ì†ë„)
            Z = linkage(X[idx], method="ward")
            dists = Z[:,2]; gaps = np.diff(dists)
            if len(gaps) >= 1:
                k_est = m - (int(np.argmax(gaps))+1)
                votes["dendrogram"] = max(2, min(k_est, ks[-1]))
    except Exception:
        pass
    vals = [v for v in [votes.get("silhouette"), votes.get("elbow"), votes.get("dendrogram")] if v is not None]
    return (int(np.median(vals)) if vals else 3), votes

k_final, votes = choose_k_multi(X, ks)
st.caption(f"ì„ íƒëœ k = {k_final} (Sil={votes.get('silhouette','â€”')}, "
           f"Elbow={votes.get('elbow','â€”')}, Dend={votes.get('dendrogram','â€”')} â†’ median)")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í•™ìŠµ & ë¼ë²¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
labels = KMeans(n_clusters=k_final, random_state=42, n_init=10).fit_predict(X)
sub_all = sub_all.copy(); sub_all["cluster"] = labels
clusters = sorted(sub_all["cluster"].unique())

# â”€â”€ ìœ í‹¸: fig â†’ png, base64
def fig_to_png(fig, dpi=160):
    buf = BytesIO(); fig.savefig(buf, format="png", dpi=dpi, bbox_inches="tight"); plt.close(fig)
    return buf.getvalue()

def to_b64(png_bytes): return base64.b64encode(png_bytes).decode("utf-8")

# â”€â”€ ê³µí†µ CSS(ê°€ë¡œ ìŠ¤í¬ë¡¤)
st.markdown("""
<style>
.scroll-x { overflow-x:auto; padding:8px 0 10px; }
.scroll-row { display:inline-flex; gap:16px; }
.scroll-row img { border-radius:12px; box-shadow:0 2px 8px rgba(0,0,0,.12); }
.caption-center { text-align:center; color:#6b7280; font-size:12px; }
</style>
""", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²°ê³¼ ê·¸ë˜í”„(ê°€ë¡œ ìŠ¤í¬ë¡¤) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
main_images = []  # (caption, png_bytes)

# PCA 2D
p2 = PCA(2, random_state=42).fit_transform(X)
fig = plt.figure(figsize=(5.2, 4.0))
plt.scatter(p2[:,0], p2[:,1], c=labels, cmap="tab10", s=55, edgecolors="k", alpha=0.9)
plt.title(f"{choice}: PCA 2D (k={k_final})"); plt.xlabel("PC1"); plt.ylabel("PC2"); plt.tight_layout()
png = fig_to_png(fig); main_images.append(("PCA 2D", png))

# Radar (í´ëŸ¬ìŠ¤í„° í‰ê· , 0~1 ì •ê·œí™”)
mean_matrix = sub_all.groupby("cluster")[num_pool].mean()
norm_means = mean_matrix.copy()
for c in num_pool:
    mn, mx = df[c].min(), df[c].max()
    norm_means[c] = 0.5 if (pd.isna(mn) or pd.isna(mx) or mx==mn) else (norm_means[c]-mn)/(mx-mn)

angles = [i/len(num_pool)*2*pi for i in range(len(num_pool))] + [0]
fig = plt.figure(figsize=(5.2, 4.0)); ax = plt.subplot(111, polar=True)
for i in clusters:
    vals = norm_means.loc[i].tolist() + [norm_means.loc[i].tolist()[0]]
    ax.plot(angles, vals, label=f"Cluster {i}"); ax.fill(angles, vals, alpha=0.1)
ax.set_xticks(angles[:-1]); ax.set_xticklabels(num_pool)
plt.title(f"{choice}: Radar (k={k_final})"); plt.legend(loc="upper right", bbox_to_anchor=(1.25,1.05))
png = fig_to_png(fig); main_images.append(("Radar", png))

# t-SNE 2D (ì˜µì…˜)
if show_tsne:
    perp = min(perplexity, n-1)
    ts2 = TSNE(n_components=2, perplexity=perp, max_iter=500, random_state=42, init="pca").fit_transform(X)
    fig = plt.figure(figsize=(5.2, 4.0))
    plt.scatter(ts2[:,0], ts2[:,1], c=labels, cmap="tab10", s=55, edgecolors="k", alpha=0.9)
    plt.title(f"{choice}: t-SNE 2D (k={k_final})"); plt.xlabel("t-SNE1"); plt.ylabel("t-SNE2"); plt.tight_layout()
    png = fig_to_png(fig); main_images.append(("t-SNE 2D", png))

# PCA 3D (ì˜µì…˜)
if show_pca3:
    from mpl_toolkits.mplot3d import Axes3D  # noqa: F401
    p3 = PCA(3, random_state=42).fit_transform(X)
    fig = plt.figure(figsize=(5.6, 4.2)); ax3 = fig.add_subplot(111, projection="3d")
    ax3.scatter(p3[:,0], p3[:,1], p3[:,2], c=labels, cmap="tab10", s=50, edgecolors="k", alpha=0.85)
    ax3.set_title(f"{choice}: PCA 3D (k={k_final})"); ax3.set_xlabel("PC1"); ax3.set_ylabel("PC2"); ax3.set_zlabel("PC3")
    png = fig_to_png(fig); main_images.append(("PCA 3D", png))

# í™”ë©´ í‘œì‹œ(ê°€ë¡œ ìŠ¤í¬ë¡¤)
html_imgs = "".join([f"<img src='data:image/png;base64,{to_b64(p)}' height='320'/>" for _,p in main_images])
st.markdown(f"<div class='scroll-x'><div class='scroll-row'>{html_imgs}</div></div>", unsafe_allow_html=True)
st.markdown("<div class='caption-center'>ì¢Œìš° ìŠ¤í¬ë¡¤ë¡œ ê²°ê³¼ ê·¸ë˜í”„(PCA2D, Radar, ì˜µì…˜: t-SNE/PCA3D)ë¥¼ í™•ì¸í•˜ì„¸ìš”.</div>", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¶”ê°€ í”„ë¡œíŒŒì¼(ê°€ë¡œ ìŠ¤í¬ë¡¤) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
profile_images = []
if show_profiles:
    # Boxplots
    for col in num_pool:
        fig = plt.figure(figsize=(6,4)); sns.boxplot(x="cluster", y=col, data=sub_all, palette="tab10")
        plt.title(f"{choice}: {col} by Cluster (k={k_final})")
        profile_images.append((f"Box {col}", fig_to_png(fig)))
    # Count & Stacked
    if "CellBalance" in sub_all.columns:
        fig = plt.figure(figsize=(6,4))
        sns.countplot(x="cluster", hue="CellBalance", data=sub_all, palette="Set2")
        plt.title(f"{choice}: Count of CellBalance by Cluster")
        profile_images.append(("Count CellBalance", fig_to_png(fig)))

        ctab_pct = pd.crosstab(sub_all["cluster"], sub_all["CellBalance"], normalize="index")*100
        ctab_pct = ctab_pct.reindex(clusters, fill_value=0)
        fig = plt.figure(figsize=(6,4)); ax = plt.gca()
        ctab_pct.plot(kind="bar", stacked=True, colormap="Paired", ax=ax)
        plt.title(f"{choice}: CellBalance Distribution (%) by Cluster"); plt.tight_layout()
        profile_images.append(("Stacked CellBalance", fig_to_png(fig)))
    # Heatmap
    mean_matrix = sub_all.groupby("cluster")[num_pool].mean()
    fig = plt.figure(figsize=(6,4))
    sns.heatmap(mean_matrix, annot=True, cmap="coolwarm", fmt=".2f")
    plt.title(f"{choice}: Numeric Feature Means per Cluster")
    profile_images.append(("Heatmap Means", fig_to_png(fig)))

    html_prof = "".join([f"<img src='data:image/png;base64,{to_b64(p)}' height='300'/>" for _,p in profile_images])
    st.markdown(f"<div class='scroll-x'><div class='scroll-row'>{html_prof}</div></div>", unsafe_allow_html=True)
    st.markdown("<div class='caption-center'>ì¶”ê°€ í”„ë¡œíŒŒì¼ë„ ê°€ë¡œ ìŠ¤í¬ë¡¤ë¡œ í™•ì¸í•˜ì„¸ìš”.</div>", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ GPT ìš”ì•½ (Chat Completions) & Word ë‚´ë³´ë‚´ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ§  ë¯¿:ìŒ ë¶„ì„ê²°ê³¼ & Word ë‚´ë³´ë‚´ê¸°")

# ì„¸ì…˜ ìƒíƒœ ì €ì¥
if "ai_text" not in st.session_state:
    st.session_state.ai_text = None

def summarize_compact(dfm: pd.DataFrame, num_pool: list[str]) -> str:
    """í”„ë¡¬í”„íŠ¸ìš© Compact í†µê³„(ì…ë ¥ í† í° ì ˆì•½)"""
    counts = dfm["cluster"].value_counts().sort_index()
    means  = dfm.groupby("cluster")[num_pool].mean()
    line_counts = f"N={len(dfm)}, k={dfm['cluster'].nunique()}"
    line_means  = " | ".join([
        "C{}: ".format(c) + ", ".join([f"{col} {means.loc[c,col]:.1f}" for col in num_pool])
        for c in counts.index
    ])
    return line_counts + "\n" + line_means

def generate_ai_summary(model: str,
                        k_final: int,
                        votes: dict,
                        dfm: pd.DataFrame,
                        num_pool: list[str],
                        model_name: str,
                        max_tokens: int,
                        temperature: float) -> str:
    stats_compact = summarize_compact(dfm, num_pool)
    try:
        if not _has_openai:
            raise RuntimeError("openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

        # â† ì—¬ê¸°! í†µí•© í—¬í¼ë¡œ ê°€ì ¸ì˜´
        api_key, model_from_secret = get_openai_conf()
        # secretsì— ëª¨ë¸ëª…ì´ ìˆìœ¼ë©´ ë®ì–´ì”€
        if model_from_secret:
            model_name = model_from_secret
        if not api_key:
            raise RuntimeError("OPENAI_API_KEY not set")

        from openai import OpenAI
        client = OpenAI(api_key=api_key)

        system_msg = (
            "You are a concise Korean data analyst. "
            "êµ°ì§‘ë¶„ì„ ê²°ê³¼ë¥¼ 250~350ì í•œêµ­ì–´ ë³¸ë¬¸ìœ¼ë¡œ ìš”ì•½í•˜ë¼. "
            "êµ°ì§‘ë³„ (ì—°ì‹Â·SoHÂ·ê°€ê²©) ë¹„êµì™€ ì‹¤ë¬´ í™œìš© í¬ì¸íŠ¸ 2~3ê°œ í¬í•¨. "
            "ë¶ˆí•„ìš”í•œ í‘œ/ì´ëª¨ì§€/ëª©ë¡ì€ ì§€ì–‘."
        )
        user_prompt = (
            f"[ëª¨ë¸]{model}\n"
            f"[ìµœì¢… k] {k_final} (Sil={votes.get('silhouette')}, "
            f"Elbow={votes.get('elbow')}, Dend={votes.get('dendrogram')})\n"
            f"[ìš”ì•½í†µê³„]\n{stats_compact}"
        )

        resp = client.chat.completions.create(
            model=model_name,            # ì˜ˆ: gpt-4o-mini
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user",   "content": user_prompt},
            ],
            temperature=temperature,
            max_tokens=max_tokens,
        )
        return resp.choices[0].message.content.strip()

    except Exception as e:
        # ì‹¤íŒ¨ ì‹œ ë¡œì»¬ ìš”ì•½(ë¹„ìš© 0ì›)
        cluster_means = dfm.groupby("cluster")[num_pool].mean().round(1)
        top_price = cluster_means["Price"].idxmax() if "Price" in cluster_means.columns else "â€”"
        return (
            f"[ë¡œì»¬ ìš”ì•½] {model}ì„(ë¥¼) k={k_final}ë¡œ êµ°ì§‘í™”í–ˆìŠµë‹ˆë‹¤. "
            f"SoHÂ·ì—°ì‹Â·ê°€ê²© í‰ê·  ê¸°ì¤€ êµ°ì§‘ ê°„ ì°¨ì´ê°€ í™•ì¸ë©ë‹ˆë‹¤. "
            f"SoHÂ·ê°€ê²©ì´ ë†’ì€ êµ°ì§‘({top_price})ì€ ë¦¬ë§ˆì¼€íŒ… íƒ€ê¹ƒ, ì €SoH êµ°ì§‘ì€ ì •ë°€ ì ê²€ ê¶Œê³ ê°€ ìœ íš¨í•©ë‹ˆë‹¤."
        )


# â”€â”€ Word ë„êµ¬: í•œê¸€ í°íŠ¸ ì ìš©
def _apply_korean_fonts(doc, font_name="Malgun Gothic", size_pt=11):
    style = doc.styles["Normal"]
    style.font.name = font_name
    style.font.size = Pt(size_pt)
    rpr = style._element.get_or_add_rPr()
    rFonts = rpr.get_or_add_rFonts()
    rFonts.set(qn("w:eastAsia"), font_name)
    rFonts.set(qn("w:ascii"), font_name)
    rFonts.set(qn("w:hAnsi"), font_name)
    for h in ["Heading 1", "Heading 2", "Heading 3"]:
        if h in doc.styles:
            st_h = doc.styles[h]
            st_h.font.name = font_name
            rpr = st_h._element.get_or_add_rPr()
            rFonts = rpr.get_or_add_rFonts()
            rFonts.set(qn("w:eastAsia"), font_name)
            rFonts.set(qn("w:ascii"), font_name)
            rFonts.set(qn("w:hAnsi"), font_name)

def export_word(
    doc_title: str,
    model: str,
    gpt_analysis_text: str,
    main_imgs: list[tuple[str, bytes]],
    profile_imgs: list[tuple[str, bytes]],
    dfm: pd.DataFrame,
    num_pool: list[str],
    votes: dict,
    k_final: int,
    template_path: Path | None = None,
    font_name: str = "Malgun Gothic"
) -> BytesIO:
    if template_path and template_path.exists():
        doc = Document(str(template_path))
    else:
        doc = Document()
    _apply_korean_fonts(doc, font_name=font_name, size_pt=11)

    # í‘œì§€/ë©”íƒ€
    doc.add_heading(doc_title, level=0)
    doc.add_paragraph(f"ëª¨ë¸: {model}")
    doc.add_paragraph(f"ìµœì¢… k: {k_final}  (Sil={votes.get('silhouette')}, Elbow={votes.get('elbow')}, Dend={votes.get('dendrogram')})")

    # ë¶„ì„ ê²°ê³¼ (GPT ìƒì„±)
    doc.add_heading("ë¶„ì„ ê²°ê³¼ (GPT ìƒì„±)", level=1)
    for para in gpt_analysis_text.split("\n"):
        if para.strip():
            doc.add_paragraph(para.strip())

    # ì£¼ìš” ì‹œê°í™”
    doc.add_heading("ì£¼ìš” ì‹œê°í™”", level=1)
    for cap, png in main_imgs:
        doc.add_paragraph(cap)
        doc.add_picture(BytesIO(png), width=Inches(6.2))

    # í´ëŸ¬ìŠ¤í„° ìš”ì•½ í†µê³„
    doc.add_heading("í´ëŸ¬ìŠ¤í„° ìš”ì•½ í†µê³„", level=1)
    counts = dfm["cluster"].value_counts().sort_index()
    means  = dfm.groupby("cluster")[num_pool].mean().round(2)
    tbl = doc.add_table(rows=1, cols=2 + len(num_pool))
    hdr = tbl.rows[0].cells
    hdr[0].text = "Cluster"; hdr[1].text = "Count"
    for i, c in enumerate(num_pool, start=2): hdr[i].text = f"Mean {c}"
    for c in counts.index:
        row = tbl.add_row().cells
        row[0].text = str(c); row[1].text = str(int(counts[c]))
        for i, col in enumerate(num_pool, start=2): row[i].text = str(means.loc[c, col])

    # ì¶”ê°€ í”„ë¡œíŒŒì¼
    if profile_imgs:
        doc.add_heading("ì¶”ê°€ í”„ë¡œíŒŒì¼", level=1)
        for cap, png in profile_imgs:
            doc.add_paragraph(cap)
            doc.add_picture(BytesIO(png), width=Inches(6.2))

    bio = BytesIO(); doc.save(bio); bio.seek(0)
    return bio

# â”€â”€ UI: ë²„íŠ¼ & ì¶œë ¥
if "ai_text" not in st.session_state:
    st.session_state.ai_text = None

col_a, col_b = st.columns([1,2])
with col_a:
    gen_btn = st.button("ğŸ§  ë¶„ì„ê²°ê³¼ ìƒì„± & Wordë¡œ ì €ì¥", use_container_width=True)
with col_b:
    if st.session_state.ai_text:
        st.markdown("**ğŸ” ë¶„ì„ ê²°ê³¼ (GPT ìƒì„±)**")
        st.write(st.session_state.ai_text)

if gen_btn:
    with st.spinner("GPT ë¶„ì„ê²°ê³¼ ìƒì„± ë° Word ë¬¸ì„œ ì‘ì„± ì¤‘..."):
        ai_text = generate_ai_summary(
            model=choice,
            k_final=k_final,
            votes=votes,
            dfm=sub_all,
            num_pool=num_pool,
            model_name=MODEL_NAME,       # ì €ê°€ ëª¨ë¸
            max_tokens=MAX_TOKENS,       # ì‘ë‹µ ìƒí•œ
            temperature=TEMPERATURE
        )
        st.session_state.ai_text = ai_text

        TEMPLATE_PATH = Path("data/EV_Battery_Report_Full.docx")  # ìˆìœ¼ë©´ ìŠ¤íƒ€ì¼ ìƒì†, ì—†ìœ¼ë©´ ë¬´ì‹œ
        template_to_use = TEMPLATE_PATH if TEMPLATE_PATH.exists() else None

        word_buf = export_word_like_full(
    doc_title=f"EV ë°°í„°ë¦¬ êµ°ì§‘ ë¶„ì„ ë³´ê³ ì„œ â€“ {choice}",
    model=choice,
    gpt_analysis_text=ai_text,                  # GPT ìš”ì•½(í•œê¸€)
    main_imgs=main_images,
    profile_imgs=profile_images if show_profiles else [],
    dfm=sub_all,
    num_pool=num_pool,
    votes=votes,
    k_final=k_final,
    font_name="Malgun Gothic"                   # í•œê¸€ í°íŠ¸
)

    st.success("ë³´ê³ ì„œë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
    st.download_button(
        "â¬‡ï¸ Word íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
        data=word_buf,
        file_name=f"EV_Battery_Report_{choice}.docx",
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        use_container_width=True,
    )

import os
from openai import OpenAI
import streamlit as st

api_key = st.secrets.get("OPENAI_API_KEY") or os.environ.get("OPENAI_API_KEY")
if api_key:
    try:
        client = OpenAI(api_key=api_key)
        r = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"user", "content":"í•œ ì¤„ë¡œ ëŒ€ë‹µ: ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ ì—¬ë¶€ë§Œ ë§í•´ì¤˜."}],
            max_tokens=10,
            temperature=0.0,
        )
        st.success("ì‘ë‹µ: " + r.choices[0].message.content)
    except Exception as e:
        st.error(f"API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
