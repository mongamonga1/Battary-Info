# -*- coding: utf-8 -*-
"""Forest LSTM

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VP7e4PqCx8JgMWqrgHiDQXoRcnmiCbW1
"""

import os, re, io, sys, math, json, textwrap, warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest

# PyTorch (LSTM용) 사용 가능 여부
try:
    import torch
    from torch import nn
    TORCH_AVAILABLE = True
except Exception:
    TORCH_AVAILABLE = False

from google.colab import files

# -----------------------------
# 1) 설정값
# -----------------------------
SEED = 42
np.random.seed(SEED)

CUTOFF_DATE = pd.Timestamp("2025-07-27")   # 학습에 포함할 마지막 날짜(누설 방지)
CONTAMINATION = 0.02                       # IF 목표 이상 비율(1~3% 권장)
RUN_LSTM = True                            # 가능하면 LSTM도 수행(미지원 시 자동 건너뜀)
MIN_TXN_FOR_LSTM = 40                      # LSTM 대상 판매업체 최소 거래수
SEQ_LEN = 12                               # LSTM 시퀀스 길이
LSTM_EPOCHS = 40
LSTM_LR = 1e-3
LSTM_BATCH = 64
LSTM_HIDDEN = 16
LSTM_LAYERS = 1

OUTPUT_DIR = "/content/outputs"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# -----------------------------
# 2) 유틸 함수
# -----------------------------
def parse_money(x):
    if pd.isna(x):
        return np.nan
    s = re.sub(r"[^\d\-]", "", str(x))
    return float(s) if s else np.nan

def to_datetime(x):
    try:
        return pd.to_datetime(x)
    except Exception:
        return pd.NaT

def minmax(arr):
    mn, mx = np.nanmin(arr), np.nanmax(arr)
    if not np.isfinite(mn) or not np.isfinite(mx) or mx - mn == 0:
        return np.zeros_like(arr, dtype=float)
    return (arr - mn) / (mx - mn)

def add_expanding_stats(df, group_cols, target, prefix):
    df = df.copy()
    grp = df.groupby(group_cols, group_keys=False)
    df[f"{prefix}_mean"] = grp[target].apply(lambda s: s.shift().expanding().mean())
    df[f"{prefix}_std"]  = grp[target].apply(lambda s: s.shift().expanding().std())
    df[f"{prefix}_cnt"]  = grp[target].apply(lambda s: s.shift().expanding().count())
    return df

def z_from(val, mean, std):
    std = std.replace(0, np.nan)
    return (val - mean) / std

def prior_partner_count(df_in):
    df_in = df_in.sort_values("계약일")
    out = pd.Series(index=df_in.index, dtype=float)
    for _, g in df_in.groupby("판매업체"):
        seen = set()
        counts = []
        for _, row in g.iterrows():
            counts.append(len(seen))
            seen.add(row["구매업체"])
        out.loc[g.index] = counts
    return out

# -----------------------------
# 3) LSTM 오토인코더 정의(선택)
# -----------------------------
class LSTMAE(nn.Module):
    def __init__(self, input_dim, hidden_size=16, num_layers=1):
        super().__init__()
        self.encoder = nn.LSTM(input_dim, hidden_size, num_layers=num_layers, batch_first=True)
        self.decoder = nn.LSTM(hidden_size, input_dim, num_layers=num_layers, batch_first=True)
    def forward(self, x):
        z, _ = self.encoder(x)
        last = z[:, -1:, :]
        last_rep = last.repeat(1, x.size(1), 1)
        out, _ = self.decoder(last_rep)
        return out

def make_sequences(arr, seq_len):
    return np.stack([arr[i:i+seq_len] for i in range(len(arr)-seq_len+1)])

# -----------------------------
# 4) CSV 업로드
# -----------------------------
df = pd.read_csv('/content/통합거래내역.csv', encoding="utf-8-sig")
print(f"읽은 파일: {csv_name}, shape={df.shape}")

# -----------------------------
# 5) 정제
# -----------------------------
import numpy as np

# 실제 남아 있는 화폐/콤마 형태를 모두 지우고 float 변환
for col in ["개당가격","총계약금액","계약보증금"]:
    if col in df.columns:
        df[col] = (
            df[col].astype(str)
                  .str.replace(r"[^\d\-]", "", regex=True)  # 숫자·하이픈 빼고 모두 제거
                  .replace("", np.nan)                      # 빈 문자열 → NaN
                  .astype(float)
        )
        print(f"✔ 정제 완료: {col} (dtype={df[col].dtype})")
money_cols = ["개당 가격", "총계약금액", "계약보증금"]
for c in money_cols:
    if c in df.columns:
        df[c] = df[c].apply(parse_money)

date_cols = ["계약일", "총지급일"]
for c in date_cols:
    if c in df.columns:
        df[c] = df[c].apply(to_datetime)

df["지급지연일수"] = (df["총지급일"] - df["계약일"]).dt.days
df["보증금율"] = df["계약보증금"] / df["총계약금액"]
df["총계약단가"] = df["총계약금액"] / df["계약수량(단위당)"].replace(0, np.nan)

df = df.sort_values("계약일").reset_index(drop=True)
train_mask = df["계약일"] <= CUTOFF_DATE
df_train = df[train_mask].copy()

# -----------------------------
# 6) 피처링
# -----------------------------
df_feat = df.copy()
cat_cols = ["판매업체", "구매업체", "제품구분", "배터리종류", "지급형태"]
for c in cat_cols:
    freq = df_train[c].value_counts()
    df_feat[f"{c}_freq"] = df_feat[c].map(freq).fillna(0)

df_feat["key_판매구매"] = df_feat["판매업체"].astype(str) + "∥" + df_feat["구매업체"].astype(str)
df_feat["key_판매제품배터리"] = (
    df_feat["판매업체"].astype(str) + "∥" +
    df_feat["제품구분"].astype(str) + "∥" +
    df_feat["배터리종류"].astype(str)
)

seen_판매구매 = set(df_train["판매업체"].astype(str) + "∥" + df_train["구매업체"].astype(str))
seen_판매제품배터리 = set(
    df_train["판매업체"].astype(str) + "∥" +
    df_train["제품구분"].astype(str) + "∥" +
    df_train["배터리종류"].astype(str)
)
df_feat["신규_판매구매"] = (~df_feat["key_판매구매"].isin(seen_판매구매)).astype(int)
df_feat["신규_판매제품배터리"] = (~df_feat["key_판매제품배터리"].isin(seen_판매제품배터리)).astype(int)

for tcol, pfx in [
    ("개당가격",        "판매업체_unit_price"),
    ("총계약금액",      "판매업체_total_amount"),
    ("보증금율",       "판매업체_deposit_rate"),
    ("지급지연일수",    "판매업체_delay_days"),
    ("계약수량(단위당)", "판매업체_qty"),
]:
    if tcol in df_feat.columns:
        df_feat = add_expanding_stats(df_feat, ["판매업체"], tcol, pfx)
    else:
        print(f"⚠️ 컬럼 누락: {tcol}")

df_feat["z_unit_price"]   = z_from(df_feat["개당가격"], df_feat["판매업체_unit_price_mean"], df_feat["판매업체_unit_price_std"])
df_feat["z_total_amount"] = z_from(df_feat["총계약금액"], df_feat["판매업체_total_amount_mean"], df_feat["판매업체_total_amount_std"])
df_feat["z_deposit_rate"] = z_from(df_feat["보증금율"], df_feat["판매업체_deposit_rate_mean"], df_feat["판매업체_deposit_rate_std"])
df_feat["z_delay_days"]   = z_from(df_feat["지급지연일수"], df_feat["판매업체_delay_days_mean"], df_feat["판매업체_delay_days_std"])
df_feat["z_qty"]          = z_from(df_feat["계약수량(단위당)"], df_feat["판매업체_qty_mean"], df_feat["판매업체_qty_std"])

df_feat["판매업체_prior_partner_cnt"] = prior_partner_count(df_feat[["판매업체","구매업체","계약일"]].copy())

feature_cols = [
    "개당가격","총계약금액","계약보증금","지급지연일수","보증금율","총계약단가","계약수량(단위당)",
    "판매업체_freq","구매업체_freq","제품구분_freq","배터리종류_freq","지급 형태_freq",
    "신규_판매구매","신규_판매제품배터리",
    "z_unit_price","z_total_amount","z_deposit_rate","z_delay_days","z_qty",
    "판매업체_unit_price_cnt","판매업체_total_amount_cnt","판매업체_deposit_rate_cnt","판매업체_delay_days_cnt","판매업체_qty_cnt",
    "판매업체_prior_partner_cnt",
]
# 누락된 컬럼이 있으면 0으로 채우기
for c in feature_cols:
    if c not in df_feat.columns:
        df_feat[c] = 0.0

X_train = df_feat.loc[train_mask, feature_cols].astype(float).fillna(0.0).values
X_all   = df_feat[feature_cols].astype(float).fillna(0.0).values

scaler = StandardScaler()
X_train_s = scaler.fit_transform(X_train)
X_all_s   = scaler.transform(X_all)

# -----------------------------
# 7) Isolation Forest
# -----------------------------
if_model = IsolationForest(
    n_estimators=500,
    contamination=CONTAMINATION,
    max_samples="auto",
    bootstrap=True,
    random_state=SEED,
    n_jobs=1   # Colab 안정성
)
if_model.fit(X_train_s)
if_scores = -if_model.decision_function(X_all_s)  # 클수록 이상
df_feat["if_score"] = if_scores
df_feat["if_score_norm"] = minmax(if_scores)

# -----------------------------
# 8) (선택) LSTM 보조 스코어
# -----------------------------
df_feat["lstm_score_norm"] = np.nan
lstm_rows = []

if RUN_LSTM and TORCH_AVAILABLE:
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    lstm_feature_cols = ["개당가격","보증금율","지급지연일수","계약수량(단위당)","총계약금액"]

    counts = df_train["판매업체"].value_counts()
    target_vendors = counts[counts >= MIN_TXN_FOR_LSTM].index.tolist()

    class _LSTMAE(nn.Module):
        def __init__(self, input_dim):
            super().__init__()
            self.model = LSTMAE(input_dim, hidden_size=LSTM_HIDDEN, num_layers=LSTM_LAYERS)
        def forward(self, x):
            return self.model(x)

    for vendor in target_vendors:
        g = df_feat[df_feat["판매업체"] == vendor].sort_values("계약일").copy()
        g_train = g[g["계약일"] <= CUTOFF_DATE].copy()
        if g.shape[0] < SEQ_LEN + 1 or g_train.shape[0] < SEQ_LEN + 1:
            continue

        scaler_v = StandardScaler()
        g_train_feat = scaler_v.fit_transform(g_train[lstm_feature_cols].astype(float).fillna(0.0).values)
        g_all_feat   = scaler_v.transform(g[lstm_feature_cols].astype(float).fillna(0.0).values)

        train_seqs = make_sequences(g_train_feat, SEQ_LEN)
        all_seqs   = make_sequences(g_all_feat, SEQ_LEN)

        Xtr = torch.tensor(train_seqs, dtype=torch.float32).to(device)
        Xall = torch.tensor(all_seqs, dtype=torch.float32).to(device)

        model = _LSTMAE(len(lstm_feature_cols)).to(device)
        opt = torch.optim.Adam(model.parameters(), lr=LSTM_LR)
        loss_fn = nn.MSELoss()

        model.train()
        for _ in range(LSTM_EPOCHS):
            idx = torch.randperm(Xtr.size(0))
            for i in range(0, Xtr.size(0), LSTM_BATCH):
                sel = idx[i:i+LSTM_BATCH]
                batch = Xtr[sel]
                opt.zero_grad()
                recon = model(batch)
                loss = loss_fn(recon, batch)
                loss.backward()
                opt.step()

        model.eval()
        with torch.no_grad():
            tr_loss = ((model(Xtr) - Xtr) ** 2).mean(dim=(1,2)).cpu().numpy()
            all_loss = ((model(Xall) - Xall) ** 2).mean(dim=(1,2)).cpu().numpy()

        idx_all = g.index.to_list()
        target_row_indices = idx_all[SEQ_LEN-1:]

        p50, p99 = np.percentile(tr_loss, 50), np.percentile(tr_loss, 99)
        denom = max(p99 - p50, 1e-6)
        norm_scores = np.clip((all_loss - p50) / denom, 0, 5) / 5.0

        tmp = pd.DataFrame({
            "판매업체": vendor,
            "row_index": target_row_indices,
            "lstm_loss": all_loss,
            "lstm_score_norm": norm_scores
        })
        lstm_rows.append(tmp)

    if lstm_rows:
        lstm_df = pd.concat(lstm_rows, ignore_index=True)
        df_feat.loc[lstm_df["row_index"].values, "lstm_score_norm"] = lstm_df["lstm_score_norm"].values
    else:
        lstm_df = pd.DataFrame(columns=["row_index","lstm_loss","lstm_score_norm","판매업체"])
else:
    lstm_df = pd.DataFrame(columns=["row_index","lstm_loss","lstm_score_norm","판매업체"])

# -----------------------------
# 9) 최종 점수 결합
# -----------------------------
def combine_scores(a, b):
    if pd.isna(b):
        return a
    return max(0.6*a, 0.4*b)

df_feat["final_score"] = [combine_scores(a, b) for a, b in zip(df_feat["if_score_norm"], df_feat["lstm_score_norm"])]
# -----------------------------
# 10) Plotly 동적 시각화 (상세 hover)
# -----------------------------
import plotly.express as px

# 이상치 레이블
threshold = df_feat["final_score"].quantile(1 - CONTAMINATION)
df_feat["anomaly"] = df_feat["final_score"] >= threshold

# 2) 이상치 강조 산점도: hover_data 에 상세 컬럼 추가
fig_anom = px.scatter(
    df_feat,
    x="계약일", y="final_score",
    color="anomaly",
    color_discrete_map={False: "lightblue", True: "red"},
    title=f"Anomalies (top {int(CONTAMINATION*100)}%) Highlighted",
    labels={"계약일":"Contract Date", "final_score":"Final Score", "anomaly":"Anomaly"},
    hover_data={
        "계약번호":    True,
        "판매업체":    True,
        "구매업체":    True,
        "제품구분":    True,
        "배터리종류":  True,
        "final_score": ":.4f"
    }
)
fig_anom.update_traces(marker=dict(size=8))
fig_anom.show()

# 11) 이상치 리스트 출력
# -----------------------------
# 상위 CONTAMINATION 비율 이상치 임계값
threshold = df_feat["final_score"].quantile(1 - CONTAMINATION)

# 이상치만 필터링
anom_df = df_feat[df_feat["final_score"] >= threshold]

# 보고 싶은 컬럼만 추려서 리스트 형태로 출력
cols = ["계약번호", "계약일", "판매업체", "구매업체", "제품구분", "배터리종류", "final_score"]
print(f"\n▶ Top {int(CONTAMINATION*100)}% Anomalies ({len(anom_df)}건):\n")
print(anom_df[cols].sort_values("final_score", ascending=False).to_string(index=False))
